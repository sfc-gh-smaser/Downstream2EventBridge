{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "7rvsj2uqx3asb5j2qhai",
   "authorId": "448503205570",
   "authorName": "SMASER_SFC",
   "authorEmail": "steven.maser@snowflake.com",
   "sessionId": "ab94731f-d433-4d08-99a2-20f8501bb9b5",
   "lastEditTime": 1741031013051
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b24a803-20d0-473a-bc6f-fd341db09f5f",
   "metadata": {
    "name": "cell0",
    "collapsed": false
   },
   "source": "# Notebook #2\n## Sets up a framework for outbound event notifications sharing table stream events in Snowflake to AWS EventBridge\nPrerequisite:  Create Database called 'EVENT_MONITORING' to store this Notebook and all objects created here\n\nNotes:  \n* Make sure you have appropriate data governance in place and not exfiltrating sensitive data to a less secured location as it leaves Snowflake.\n* This sample was written with Notebook #1 to send events to AWS EventBridge, but other UDFs can be added to send to other downstream destinations including Snowflake.\n\n\nWritten by Steven.Maser@snowflake.com"
  },
  {
   "cell_type": "code",
   "id": "092c64f9-aad9-4c89-9bed-0ad6c5f4adcf",
   "metadata": {
    "language": "python",
    "name": "VARIABLES",
    "collapsed": false
   },
   "outputs": [],
   "source": "#Variables for object creation\nDB= 'EVENT_MONITORING'\nSCHEMA = 'PUBLIC'\nSUB_SCHEMA = 'PROCESSING'\nEXT_UDF = 'notifyEventBridge'",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "90ce3a31-4140-4d7e-ae43-68211ef82d20",
   "metadata": {
    "language": "sql",
    "name": "cell1",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "--1.  Create schema for individual table's streams & tasks\ncreate schema if not EXISTS {{DB}}.{{SUB_SCHEMA}};",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8d50cbf4-0c8d-4950-86cb-114990437ac9",
   "metadata": {
    "language": "sql",
    "name": "cell2",
    "collapsed": false
   },
   "source": "--2. Create table that will list what tables to be monitoring events on\nCREATE or REPLACE TABLE {{DB}}.{{SCHEMA}}.WATCHED_TABLES (\n    DB_NAME STRING COMMENT 'Database where table to monitor resides',\n    SCHEMA_NAME STRING COMMENT 'Schema where table to monitor resides',\n    TABLE_NAME STRING COMMENT 'Table to monitor',\n    EXT_UDF STRING COMMENT 'UDF/Function to call to transmit new/updated records',\n    LOAD_INITIAL BOOLEAN COMMENT 'Option to send all current records in table, or skip'\n) \nCOMMENT='This table holds the list of tables to continuously monitor changes and transmit downstream';",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "ce336879-a1c6-4eab-b0aa-eb75077c88ae",
   "metadata": {
    "language": "sql",
    "name": "cell3",
    "collapsed": false
   },
   "outputs": [],
   "source": "--3.  Create Stream to identify added tables/records to WATCHED_TABLES table\nCREATE or REPLACE STREAM {{DB}}.{{SCHEMA}}.WATCHED_TABLES_STRM ON TABLE {{DB}}.{{SCHEMA}}.WATCHED_TABLES;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "20976e4b-2753-4df1-8b14-4ac4310bd54f",
   "metadata": {
    "language": "sql",
    "name": "cell4",
    "codeCollapsed": false,
    "collapsed": false
   },
   "outputs": [],
   "source": "--4. Create triggered to task to run when table(s) are added to be monitored.  \n      ---This task will create a stream and a task for each added table that will send events for each new record in that table.\nCREATE or REPLACE TASK {{DB}}.{{SCHEMA}}.TABLE_ADDED_TSK\n  COMMENT='This Task sets up sending changes downstream for tables registered in table WATCHED_TABLES'\n  TARGET_COMPLETION_INTERVAL='1 MINUTE'\n  SUSPEND_TASK_AFTER_NUM_FAILURES=1\n  WHEN SYSTEM$STREAM_HAS_DATA('{{DB}}.{{SCHEMA}}.WATCHED_TABLES_STRM')\n  AS\n  DECLARE  \n    c1 CURSOR FOR SELECT DB_NAME,SCHEMA_NAME,TABLE_NAME,LOAD_INITIAL,EXT_UDF,METADATA$ACTION as ACTION from {{DB}}.{{SCHEMA}}.WATCHED_TABLES_STRM;\n    stream_name VARCHAR;\n    task_name VARCHAR;\n    table_counter INTEGER default 0;\n    BEGIN   \n      open c1;\n      FOR rec IN c1 DO\n        LET action string:=rec.ACTION::STRING;\n        IF ( action = 'INSERT' ) THEN\n          table_counter:= table_counter+1;\n          LET db_name string:=rec.DB_NAME::STRING;\n          LET schema_name string:=rec.SCHEMA_NAME::STRING;\n          LET table_prefix string:=db_name || '_' || schema_name || '_' || rec.TABLE_NAME::STRING;\n          LET table_name string:=db_name || '.' || schema_name || '.' || rec.TABLE_NAME::STRING;\n          LET load_initial string:=rec.load_initial::BOOLEAN;\n          LET ext_edf string:=rec.EXT_UDF::STRING;\n          LET stream_name string:=table_prefix || '_STRM';\n          LET task_name string:=table_prefix||'_TASK';\n          LET temp_table string:=table_prefix||'_tmp';\n          LET task_sql1 string:='BEGIN';\n          LET task_sql2 string:='SELECT ' || ext_edf || '(OBJECT_CONSTRUCT(\\'Account\\',current_account(), \\'Region\\',current_region(), \\'Database\\',\\'' || db_name || '\\', \\'Schema\\',\\'' || schema_name ||'\\', \\'Table\\',\\'' || table_name || '\\', \\'Record\\',OBJECT_CONSTRUCT(*))::STRING) as EventId FROM {{DB}}.{{SUB_SCHEMA}}.' || stream_name || ';';\n          LET task_sql3 string:='LET num_rows INTEGER := (select count(*) from TABLE(RESULT_SCAN(LAST_QUERY_ID())));';\n          LET task_sql4 string:='LET return_value STRING := :num_rows::STRING || \\' row(s) sent\\';';\n          LET task_sql5 string:='CALL SYSTEM$SET_RETURN_VALUE(:return_value);';\n          --LET task_sql6 string:='CREATE or REPLACE TEMP TABLE tmp_empty_stream AS (SELECT * FROM {{DB}}.{{SUB_SCHEMA}}.' || stream_name ||' WHERE FALSE);';\n          LET task_sql6 string:='CREATE or REPLACE TEMP TABLE '|| temp_table ||' AS (SELECT * FROM {{DB}}.{{SUB_SCHEMA}}.' || stream_name ||' WHERE FALSE);';\n          LET task_sql7 string:='END;';\n          let ret string:='\n          ';\n          LET task_sql string := task_sql1||ret||task_sql2||ret||task_sql3||ret||task_sql4||ret||task_sql5||ret||task_sql6||ret||task_sql7;\n          LET stmt1 string:='CREATE OR REPLACE STREAM {{DB}}.{{SUB_SCHEMA}}.'||stream_name|| ' ON TABLE ' || table_name || ' SHOW_INITIAL_ROWS=' || load_initial;\n          LET stmt2 string:='CREATE OR REPLACE TASK {{DB}}.{{SUB_SCHEMA}}.' || task_name || ' TARGET_COMPLETION_INTERVAL=\\'1 MINUTE\\' SUSPEND_TASK_AFTER_NUM_FAILURES=1 WHEN SYSTEM$STREAM_HAS_DATA(\\'{{DB}}.{{SUB_SCHEMA}}.'|| stream_name ||'\\') AS ' || task_sql;\n          LET stmt3 string:='ALTER TASK {{DB}}.{{SUB_SCHEMA}}.' || task_name || ' RESUME;';  \n          LET stmt4 string:='CREATE or REPLACE TEMP TABLE WATCHED_TABLES_TMP AS (SELECT * FROM {{DB}}.{{SCHEMA}}.WATCHED_TABLES_STRM WHERE FALSE);';\n          EXECUTE IMMEDIATE :stmt1;\n          EXECUTE IMMEDIATE :stmt2;\n          EXECUTE IMMEDIATE :stmt3;\n          EXECUTE IMMEDIATE :stmt4;\n        END IF;  -- currently not processing update/deletes\n      END FOR;  \n      CLOSE c1;\n    LET return_val STRING:=table_counter::STRING || ' table(s) added for event monitoring';\n    CALL SYSTEM$SET_RETURN_VALUE(:return_val);\n    END;\n;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b33c2dc2-6f8d-41a0-9991-ce1ce8d04bb9",
   "metadata": {
    "language": "sql",
    "name": "cell5",
    "collapsed": false
   },
   "outputs": [],
   "source": "--5.  Activate this task to begin\nALTER TASK {{DB}}.{{SCHEMA}}.TABLE_ADDED_TSK RESUME;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "90d42461-f5d1-454e-a0e5-9d912500fe9a",
   "metadata": {
    "language": "sql",
    "name": "cell6",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "--6. create a new table and register it for event sending\ncreate or replace table {{DB}}.{{SCHEMA}}.TEST_TABLE(NUM INTEGER,NAME STRING);\n\n---- Insert sample/your table to monitor and send change events\nINSERT INTO {{DB}}.{{SCHEMA}}.WATCHED_TABLES values ('{{DB}}','{{SCHEMA}}','TEST_TABLE','{{EXT_UDF}}', true);\n\nSELECT * from {{DB}}.{{SCHEMA}}.WATCHED_TABLES_STRM;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "55a96789-99b7-44b0-ab6f-3dfa80dc37ff",
   "metadata": {
    "language": "sql",
    "name": "cell7",
    "collapsed": false
   },
   "outputs": [],
   "source": "--7. add records to TEST_TABLE\nCALL SYSTEM$WAIT(20);\nINSERT INTO {{DB}}.{{SCHEMA}}.TEST_TABLE values (1,'apple');\nINSERT INTO {{DB}}.{{SCHEMA}}.TEST_TABLE values (2,'pear');\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b102cd2e-9119-49fa-8e09-008161d8bfec",
   "metadata": {
    "language": "sql",
    "name": "cell8",
    "collapsed": false
   },
   "outputs": [],
   "source": "--8. add more records to TEST_TABLE\nCALL SYSTEM$WAIT(20);\nINSERT INTO {{DB}}.{{SCHEMA}}.TEST_TABLE values (3,'banana');\nINSERT INTO {{DB}}.{{SCHEMA}}.TEST_TABLE values (4,'orange');\nINSERT INTO {{DB}}.{{SCHEMA}}.TEST_TABLE values (4,'grape');",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4a0b9132-0448-4903-b5fc-ca91c2d5973f",
   "metadata": {
    "language": "sql",
    "name": "cell9",
    "collapsed": false
   },
   "outputs": [],
   "source": "--9. create a another larger table, seed with some records, and register it for event sending\ncreate or replace table {{DB}}.{{SCHEMA}}.TEST_TABLE2 as select * from SNOWFLAKE_SAMPLE_DATA.TPCH_SF1.CUSTOMER limit 1000;\n\nINSERT INTO {{DB}}.{{SCHEMA}}.WATCHED_TABLES values ('{{DB}}','{{SCHEMA}}','TEST_TABLE2','{{EXT_UDF}}', true);\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c96e160f-fba9-494d-93aa-116cbeaabfa7",
   "metadata": {
    "language": "sql",
    "name": "cell10",
    "collapsed": false
   },
   "outputs": [],
   "source": "--10. Micro-batch a stream of records into table for testing\nset endtime=DATEADD ('minute', 1, CURRENT_TIMESTAMP());\nset batchsize=100;\n\nEXECUTE IMMEDIATE \n$$ BEGIN\n  WHILE ($endtime >CURRENT_TIMESTAMP()) do\n        INSERT INTO {{DB}}.{{SCHEMA}}.TEST_TABLE2  select * from SNOWFLAKE_SAMPLE_DATA.TPCH_SF1.CUSTOMER limit $batchsize;\n        CALL SYSTEM$WAIT(1); -- throttle testing throughput, can comment out or use '0'\n  END WHILE;\nEND; $$;\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "52634a26-f368-4603-8046-e5f9e8821e43",
   "metadata": {
    "language": "sql",
    "name": "cell11",
    "collapsed": false
   },
   "outputs": [],
   "source": "--11.  When testing complete, can turn off your triggered tasks using:\n--ALTER TASK {{DB}}.{{SCHEMA}}.TABLE_ADDED_TSK SUSPEND;\n--ALTER TASK {{DB}}.{{SUB_SCHEMA}}.EVENT_MONITORING_PUBLIC_TEST_TABLE_TASK SUSPEND;\n--ALTER TASK {{DB}}.{{SUB_SCHEMA}}.EVENT_MONITORING_PUBLIC_TEST_TABLE2_TASK SUSPEND;",
   "execution_count": null
  }
 ]
}